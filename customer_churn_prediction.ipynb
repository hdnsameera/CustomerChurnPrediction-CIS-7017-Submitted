{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.D.Nuwan Sameera ( Dissertation - MSc. in Data Science ( Batch 03 ) / Cardiff Met, ICBT )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop more robust and precise models that can identify potential churners early and provide actionable insights for retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VTYtKVxjrRP"
   },
   "source": [
    "## The steps of the process of prediction used in this project\n",
    "\n",
    "- <b>Data collection</b>:\n",
    "\n",
    "The dataset contains customer behavior, interactions, and historical churn.\n",
    "\n",
    "- <b>Data preprocessing</b>:\n",
    "\n",
    "Clean and preprocess the data by handling missing values, outliers, and encoding categorical variables.         Making the dataset suitable for ML.\n",
    "     \n",
    "     \n",
    "- <b>Feature engineering</b>:\n",
    "\n",
    "Create meaningful features that can help the model make accurate predictions.\n",
    "    This involves feature scaling, normalization, or generating new features based on domain knowledge.\n",
    "    \n",
    "    \n",
    "- <b>Data splitting</b>:\n",
    "\n",
    "Split the dataset into training, validation, and test sets.\n",
    "    A common split is 70% for training, 15% for     validation, and 15% for testing.\n",
    "    The validation set is used for hyperparameter tuning.\n",
    "    \n",
    "    \n",
    "- <b>Model selection</b>:\n",
    "\n",
    "Choose the appropriate machine learning algorithms for churn prediction.\n",
    "    Common choices include K-nearest neighbors, support vector machine, logistic regression, random forests, decision trees, ada boost, gradient boosting, voting, and neural networks.\n",
    "    Consider using ensemble methods or stacking multiple models for better performance.\n",
    "\n",
    "\n",
    "- <b>Model training</b>:\n",
    "\n",
    "Train the selected models using the training dataset.\n",
    "    Tune hyperparameters to optimize model performance on the validation set.\n",
    "    This may involve techniques like cross-validation.\n",
    "\n",
    "\n",
    "- <b>Model evaluation</b>:\n",
    "\n",
    "Evaluate the model's performance using appropriate metrics such as accuracy, precision, recall,\n",
    "    F1-score, ROC AUC, or customer-centric metrics like customer lifetime value (CLV).\n",
    "    Compare the performance of different models and\n",
    "    choose the one that best aligns with your business objectives.\n",
    "\n",
    "- <b>Finalizing The Most Suitable Model</b>\n",
    "    \n",
    "- <b>Feature Importance Analysis</b>:\n",
    "\n",
    "Understand which features are most important for making churn predictions.\n",
    "    Feature importance analysis can help refine the model and provide insights into customer behavior.\n",
    "    \n",
    "    \n",
    "- <b>Model deployment</b>:\n",
    "\n",
    "Once the model with satisfactory performance is selected, it can be deployed to a production environment where it can make real-time predictions. Consider using APIs or containerization for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kewqJ0iEjrRQ"
   },
   "source": [
    "## Further steps to be followed\n",
    "\n",
    "- <b>Monitoring and Maintenance</b>:\n",
    "\n",
    "Continuously monitor the model's performance in a production environment. Re-train the model periodically with new data to ensure it remains accurate as customer behavior changes over time.\n",
    "    \n",
    "    \n",
    "- <b>Interpretability and Explainability</b>:\n",
    "\n",
    "Understand how the model is making predictions. Use techniques like SHAP values or LIME to interpret and explain model decisions to stakeholders.\n",
    "\n",
    "\n",
    "- <b>Feedback loop</b>:\n",
    "\n",
    "Incorporate feedback from business stakeholders, customer support, and other relevant sources to improve the model over time.\n",
    "    \n",
    "    \n",
    "- <b>Scale and Iterate</b>:\n",
    "\n",
    "As your business evolves and gathers more data, consider scaling the model and iterating on the process to improve prediction accuracy and reduce churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jloAKIAjrRR"
   },
   "source": [
    "## Libraries installed\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- plotly\n",
    "- ydata-profiling (!pip install -U ydata-profiling)\n",
    "- seaborn\n",
    "- sklearn\n",
    "- jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raxQvmBdjrRR"
   },
   "source": [
    "## Special Notes\n",
    "\n",
    "##### Run the below code to upgrade '<b>threadpoolctl</b>' library if the training code of <b>KNN</b> model throws an exception.\n",
    "\n",
    "    - Mac: !pip install threadpoolctl --upgrade   \n",
    "    - Windows: pip install threadpoolctl --upgrade   \n",
    "\n",
    "\n",
    "##### Run the below code to install ydata-profiling  library\n",
    "    - Mac: !pip install -U ydata-profiling\n",
    "    - Windows: pip install -U ydata-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHQOTWqjrRS"
   },
   "source": [
    "## Feature Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJLePsx_jrRV"
   },
   "source": [
    "## ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrsBlkg7jrRW"
   },
   "outputs": [],
   "source": [
    "# Libraries related to date and time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if not exist\n",
    "import os\n",
    "\n",
    "listFolders = ['fig', 'boxplots']\n",
    "\n",
    "for f in listFolders:\n",
    "\n",
    "    isExist = os.path.exists(f)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJLkklOMjrRX"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT9wZuIG_ftz"
   },
   "outputs": [],
   "source": [
    "# @title Global variables\n",
    "\n",
    "# Initialize the program started time\n",
    "mainStartTime = datetime.now()\n",
    "\n",
    "# Initialize the ML start and end time.\n",
    "startTime = datetime.now()\n",
    "endTime = datetime.now()\n",
    "\n",
    "# List of the column names\n",
    "colNames = []\n",
    "\n",
    "# Run visualization codes (1=Show Plots and other graphs)\n",
    "showViz = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAdtFhZQjrRY"
   },
   "source": [
    "##  < Data Collection >\n",
    "\n",
    "#### Two datasets are selected to the entire process.\n",
    "\n",
    "    - telcomModelData.csv - The dataset taken to train and test the models\n",
    "    - telcomHoldout.csv   - The dataset taken to predict the most accurate and appropriate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLz3JxYzjrRY"
   },
   "source": [
    "#### Importing the required libraries for data manupulation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzYxVpVs-_t4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9ZvaGPrjrRZ"
   },
   "source": [
    "#### Reading the dataset into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0XY8uwGPJd9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('telcomModelData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1695231186246,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "ErCQwEabsIw9"
   },
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1695231186247,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "PmMFlTTbgDr0",
    "outputId": "1d678e54-8685-4800-9c98-5afd68de7ee3"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1695231188890,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "c4pIF4NoOsJw",
    "outputId": "4145e4e3-c0eb-45c2-c2a9-86fde563cc65"
   },
   "outputs": [],
   "source": [
    "# Show the number of columns and rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695231190322,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "IxekJRXigIYR",
    "outputId": "ae655070-6598-41f5-f3fb-d4749d9fff29"
   },
   "outputs": [],
   "source": [
    "# Observing data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695231192219,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "LTEvrifBi-HJ",
    "outputId": "dd8ec312-e5bf-4916-9a30-71175492eba3"
   },
   "outputs": [],
   "source": [
    "# Check for unique values in dtype 'object' (categorical)\n",
    "\n",
    "def showUniqueValues(df):\n",
    "  colNames.clear()\n",
    "  for column in df:\n",
    "    colNames.append(column)\n",
    "    if df[column].dtype =='object':\n",
    "      print(f'{column} : {df[column].unique()}')\n",
    "\n",
    "showUniqueValues(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5VepUeJjrRd",
    "outputId": "d8dfa506-7bd8-4cb3-ea34-f7df7abd612c"
   },
   "outputs": [],
   "source": [
    "# List of column names\n",
    "colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1695231192800,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "Er56FN7-uVCm"
   },
   "source": [
    "## < Data preprocessing >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1695231202843,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "tvHA1PBtpy6d",
    "outputId": "b6c7119b-25cd-4344-cad9-a313c7044704"
   },
   "outputs": [],
   "source": [
    "# HandsetPrice should be numeric. A value as 'Unknown' is assigned in the column.\n",
    "# Get the number of observations where the value 'Unknown' is assigned.\n",
    "pd.to_numeric(df.HandsetPrice, errors='coerce').isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695231202844,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "Ey30d2FmrWwN",
    "outputId": "22b762ca-fa59-43e1-9b8a-bc04fdf717d6"
   },
   "outputs": [],
   "source": [
    "# Since there are observations with 'Unknown' value more than the half of the dataset, these observations cannot be dropped.\n",
    "# HandsetPrice should be numeric. A value as 'Unknown' is assigned in the column. Convert the values from char to numeric ignoring the 'Unknown' values.\n",
    "df[pd.to_numeric(df.HandsetPrice, errors='coerce').isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695231203510,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "oesyFVR2qGxn",
    "outputId": "169b2c03-d8a5-4c27-d4d6-03965169d08d"
   },
   "outputs": [],
   "source": [
    "df[df.HandsetPrice == 'Unknown'].HandsetPrice.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIhuwCFejrRh"
   },
   "source": [
    "#### Function to check for missing data or NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZR4ByElS_o8U"
   },
   "outputs": [],
   "source": [
    "def checkNA():\n",
    "  for x in df.columns:\n",
    "      if df[x].isna().sum() != 0:\n",
    "          print(x, df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695231205164,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "pUtCeaCjPIGz",
    "outputId": "823d0682-1805-49b7-98b9-21de26fd4545"
   },
   "outputs": [],
   "source": [
    "# Check NAs\n",
    "checkNA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DEvkSVtjrRj"
   },
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYNHpcZSjrRk"
   },
   "outputs": [],
   "source": [
    "def dropColumns(df):\n",
    "\n",
    "    # The 'CustomerID' is not important.\n",
    "    df.drop('CustomerID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBy6hrRAjrRk"
   },
   "outputs": [],
   "source": [
    "dropColumns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1Y9vHtKjrRl",
    "outputId": "1d417ca7-d03b-4b89-a751-9ad2808a51d0"
   },
   "outputs": [],
   "source": [
    "# Show unique values\n",
    "showUniqueValues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4snS0090jrRm"
   },
   "source": [
    "### NA imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mD3xI9kuB4Nq"
   },
   "outputs": [],
   "source": [
    "def imputeNA(df):\n",
    "\n",
    "    try:\n",
    "        df['MonthlyRevenue'].fillna(df['MonthlyRevenue'].median(), inplace=True)\n",
    "        df['MonthlyMinutes'].fillna(df['MonthlyMinutes'].median(), inplace=True)\n",
    "        df['TotalRecurringCharge'].fillna(df['TotalRecurringCharge'].median(),inplace=True)\n",
    "\n",
    "        df['AgeHH1'].fillna(value=0, inplace=True)\n",
    "        df['AgeHH2'].fillna(value=0, inplace=True)\n",
    "        df['PercChangeRevenues'].fillna(value=0,inplace=True)\n",
    "        df['PercChangeMinutes'].fillna(value=0,inplace=True)\n",
    "        df['RoamingCalls'].fillna(value=0,inplace=True)\n",
    "        df['OverageMinutes'].fillna(value=0,inplace=True)\n",
    "        df['DirectorAssistedCalls'].fillna(value=0,inplace=True)\n",
    "\n",
    "        #df['ServiceArea'].fillna(df['ServiceArea'].mode()[0], inplace=True)\n",
    "        df['Handsets'].fillna(df['Handsets'].mode()[0],inplace=True)\n",
    "        df['HandsetModels'].fillna(df['HandsetModels'].mode()[0],inplace=True)\n",
    "        df['CurrentEquipmentDays'].fillna(df['CurrentEquipmentDays'].median(),inplace=True)\n",
    "\n",
    "        # Replace 'Unknown' value with nan\n",
    "        df['HandsetPrice'] = df['HandsetPrice'].replace('Unknown', np.nan)\n",
    "        df['HandsetPrice'].fillna(df['HandsetPrice'].median(), inplace=True)\n",
    "        df['HandsetPrice'] = pd.to_numeric(df['HandsetPrice'])\n",
    "    except ZeroDivisionError as err:\n",
    "        print(err)\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "    except KeyError as err:\n",
    "        print(err, 'feature error')\n",
    "    else:\n",
    "        return df\n",
    "    finally:\n",
    "        print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9lm6a7DjrRp",
    "outputId": "745cae94-dd67-4a76-f6e4-ec20e15a0d12"
   },
   "outputs": [],
   "source": [
    "imputeNA(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MH2WVAnkPAD1"
   },
   "outputs": [],
   "source": [
    "# Check NAs\n",
    "checkNA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hvz00bQVjrRr"
   },
   "source": [
    "#### Show categorical unique values of the columns except 'ServiceArea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695231207860,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "WxdPBIpbF-_Z",
    "outputId": "93df6c4e-c95d-4aa5-b804-22874b29b114"
   },
   "outputs": [],
   "source": [
    "showUniqueValues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB2goKWqjrRs"
   },
   "source": [
    "## Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr26HA11jrRs"
   },
   "source": [
    "### Data distribution - Pie charts\n",
    "#### Churn visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695231208413,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "WcNUcQMXcuW3",
    "outputId": "d5375b24-ee54-4318-e9f1-62f32b0f21a7"
   },
   "outputs": [],
   "source": [
    "import plotly.offline as po\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "if showViz == 1:\n",
    "    churn_key = df['Churn'].value_counts().keys().tolist()\n",
    "    churn_value = df['Churn'].value_counts().values.tolist()\n",
    "\n",
    "    plot_data = [\n",
    "        go.Pie(labels=churn_key, values=churn_value, marker=dict(colors=['Teal','Gray'], line=dict(color='white', width=1.5)),\n",
    "        rotation=90,\n",
    "        hoverinfo=\"label+value+text\",\n",
    "        hole=0.6)\n",
    "    ]\n",
    "\n",
    "    plot_layout = go.Layout(dict(title=\"Customer Churn\", plot_bgcolor='rgb(243, 243,243)', paper_bgcolor='rgb(243, 243, 243)',))\n",
    "\n",
    "    fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "    po.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical type features distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1695231210721,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "f7C1BYxTcugS",
    "outputId": "f6a5f58d-30de-46ca-ad0f-d7f1d568006b"
   },
   "outputs": [],
   "source": [
    "# The following function is used to visualize the distribution of the other columns\n",
    "\n",
    "# Function to visualize the distribution\n",
    "def distributionPie(column):\n",
    "  labels = df[column].unique()\n",
    "  values = df[column].value_counts()\n",
    "\n",
    "  fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=0.6, rotation=90)])\n",
    "  fig.update_layout(title_text=f\"{column} Distribution\", plot_bgcolor='rgb(243, 243,243)')\n",
    "  fig.show()\n",
    "\n",
    "if showViz == 1:\n",
    "    # Loop the column names (categorical)\n",
    "#     for column in df.drop(['ServiceArea', 'Churn', 'HandsetPrice'], axis=1):\n",
    "    \n",
    "    for column in df.drop(['Churn', 'HandsetPrice'], axis=1):\n",
    "        if df[column].dtype =='object':\n",
    "            distributionPie(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwyPF4ksjrRu"
   },
   "source": [
    "### Pandas profiling report\n",
    "\n",
    "##### This report is an interactive data analysis report for quickly gaining insights into a dataset. The report provides a wide range of statistical and visual summaries of the data, helping data analysts and data scientists to understand the dataset's characteristics, identify potential issues, and make informed decisions about data preprocessing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXuzQkl0jrRu"
   },
   "source": [
    "#### Generating the profiling report and saving as an HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujIPp54KjrRv"
   },
   "outputs": [],
   "source": [
    "if showViz == 1:\n",
    "    # ProfileReport started time\n",
    "    startTime = datetime.now()\n",
    "\n",
    "    from ydata_profiling import ProfileReport\n",
    "\n",
    "    # Create pandas profiling report\n",
    "    profReport = ProfileReport(df)\n",
    "\n",
    "    # Download pandas profiling report in html format\n",
    "    profReport.to_file('Row Data Analysis.html')\n",
    "\n",
    "    endTime = datetime.now()\n",
    "\n",
    "    print(f'Profile Report processing time : {endTime-startTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmY_zWNQjrRv"
   },
   "source": [
    "#### View the profiling report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKQwI3dkjrRv"
   },
   "outputs": [],
   "source": [
    "# View pandas profiling report (This will take a few minutes to load the report)\n",
    "# Since this takes a considerable amount of time to load, the report is saved as 'Row Data Analysis.html' in the directory.\n",
    "# Open the exported html file to view the plots and other statistics instead.\n",
    "\n",
    "# Uncomment the below code to view the report along with the code.\n",
    "\n",
    "#profReport\n",
    "\n",
    "# Open profiling report in browser\n",
    "import webbrowser\n",
    "url = \"Row Data Analysis.html\"\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJuV_zIUjrRw"
   },
   "source": [
    "#### Visualizing the distribution of categorical features by 'Churn' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "on0AdJCDjrRw",
    "outputId": "de908759-ea10-4f65-cab8-732189f243bb"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "if showViz == 1:\n",
    "\n",
    "    for column in df.drop('Churn', axis=1):\n",
    "        \n",
    "        if df[column].dtype !='object':\n",
    "            fig, ax = plt.subplots(figsize=(6, 3))\n",
    "            sns.set_context(\"paper\",font_scale=1.1)\n",
    "            ax = sns.kdeplot(df[column][(df[\"Churn\"] == 'No') ],\n",
    "                            color=\"Red\", fill=True);\n",
    "            ax = sns.kdeplot(df[column][(df[\"Churn\"] == 'Yes') ],\n",
    "                            ax =ax, color=\"Blue\", fill=True);\n",
    "            ax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\n",
    "            ax.set_ylabel('Density');\n",
    "            ax.set_xlabel(column);\n",
    "            ax.set_title(f'Distribution of {column} by churn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1695231218398,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "tocGkMH18yVh"
   },
   "source": [
    "#### Comparing the features statistically against 'Churn' values 'Yes' and 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1695231220289,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "9fh8jiqlmQIA",
    "outputId": "1b813f02-a199-4a49-d522-43f1be4c5708"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def compareStatsWithChurn(colName):\n",
    "\n",
    "  fig = px.box(df, x='Churn', y = colName)\n",
    "\n",
    "  # Update yaxis properties\n",
    "  fig.update_yaxes(title_text=colName, row=1, col=1)\n",
    "  # Update xaxis properties\n",
    "  fig.update_xaxes(title_text='Churn', row=1, col=1)\n",
    "\n",
    "  # Update size and title\n",
    "  fig.update_layout(autosize=True, width=750, height=600,\n",
    "      title_font=dict(size=25, family='Courier'),\n",
    "      title=f'<b>{colName} vs Churn</b>',\n",
    "  )\n",
    "\n",
    "  fig.show()\n",
    "\n",
    "if showViz == 1 :\n",
    "    for c in colNames:\n",
    "        compareStatsWithChurn(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVhHugSijrRx"
   },
   "source": [
    "#### Analyzing 'Churn' vs other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5v-i37lYFfK"
   },
   "outputs": [],
   "source": [
    "# Function to analyze customer churn vs other features\n",
    "\n",
    "def churnHist(colName):\n",
    "  fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "  churn_yes = df[df.Churn=='Yes'][colName]\n",
    "  churn_no = df[df.Churn=='No'][colName]\n",
    "\n",
    "  ax.hist([churn_yes, churn_no], color=['red','purple'], label=['Yes','No'])\n",
    "  ax.legend()\n",
    "\n",
    "  ax.set(title=f'Customer churn vs {colName} analysis', xlabel=colName, ylabel='Number of customers')\n",
    "\n",
    "  plt.savefig(f'fig/{column}.png', dpi=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 92455,
     "status": "ok",
     "timestamp": 1695213391734,
     "user": {
      "displayName": "Nuwan Sameera",
      "userId": "07240712498791241499"
     },
     "user_tz": -330
    },
    "id": "Ilq4fhIsYasa",
    "outputId": "d681d8e0-c61d-4062-e253-8f4061057a75"
   },
   "outputs": [],
   "source": [
    "# Customer churn vs other features\n",
    "\n",
    "if showViz == 1:\n",
    "    for column in df.drop('Churn', axis=1):\n",
    "      churnHist(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTO6c049jrRz"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl9sp79bjrR0"
   },
   "source": [
    "#### Encoding Type 1 : Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Zz-1Fc0Reeb"
   },
   "outputs": [],
   "source": [
    "def labelEncoding(df):\n",
    "\n",
    "    # Since 'Homeownership' column has two unique values such as 'Known' and 'Unknown', label encoding is done seperately as below.\n",
    "    df['Homeownership'].replace({'Known':1, 'Unknown':0}, inplace=True)\n",
    "\n",
    "    # Defining an array to store the names of the columns where the values contain 'Yes' and 'No' only.\n",
    "    yes_no_columns = ['ChildrenInHH', 'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner', 'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers', 'OptOutMailings',\n",
    "                      'NonUSTravel' , 'OwnsComputer', 'HasCreditCard', 'NewCellphoneUser', 'NotNewCellphoneUser', 'OwnsMotorcycle', 'MadeCallToRetentionTeam']\n",
    "\n",
    "    # Loop to do label encoding to all the columns with values 'Yes' and 'No'.\n",
    "\n",
    "    for col in yes_no_columns:\n",
    "      df[col].replace({'Yes':1, 'No':0}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcF9Mpx4jrR0"
   },
   "outputs": [],
   "source": [
    "df = labelEncoding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GndMwhVjUCIw"
   },
   "outputs": [],
   "source": [
    "# Check shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7KJf-TlU67L"
   },
   "outputs": [],
   "source": [
    "# Show categorical unique values of the columns except 'ServiceArea'\n",
    "\n",
    "showUniqueValues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLGgzIC5jrR2"
   },
   "source": [
    "#### Encoding Type 2 : One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJPWLwJgUqRS"
   },
   "outputs": [],
   "source": [
    "def oneHotEncoding(df):\n",
    "    # One hot encoding is done to the relevant columns at once.\n",
    "    df = pd.get_dummies(data=df, columns=['CreditRating', 'PrizmCode', 'Occupation', 'MaritalStatus'], dtype=float)\n",
    "    return df\n",
    "\n",
    "df = oneHotEncoding(df)\n",
    "\n",
    "# Check shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Rk_vovo6jT7"
   },
   "outputs": [],
   "source": [
    "# View the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6YOOl5HURRJ"
   },
   "outputs": [],
   "source": [
    "# Show unique values of the columns\n",
    "showUniqueValues(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvJklLpgjrR4"
   },
   "outputs": [],
   "source": [
    "# Get the column names\n",
    "colNames.clear()\n",
    "for column in df:\n",
    "    colNames.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpVS4JpoR3x2"
   },
   "outputs": [],
   "source": [
    "# Show some statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0qRUrCj_9Qq"
   },
   "outputs": [],
   "source": [
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v7gB3dMjrR5"
   },
   "outputs": [],
   "source": [
    "len(colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiqfhfJMjrR6"
   },
   "source": [
    "# < Feature Engineering >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdXnI7TDjrR6"
   },
   "source": [
    "### Treating Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn7TYA3WjrR6"
   },
   "source": [
    "#### Function to show outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts_OpTozjrR6"
   },
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "# Since the number of features is 73, the boxplots are grouped as 5 features per group.\n",
    "\n",
    "def showBoxplots():\n",
    "  l1 = []\n",
    "\n",
    "  for i in range(round(len(colNames)/5)):\n",
    "    l1.append(colNames[i*5:(i+1)*5])\n",
    "    #df.boxplot(column=colNames[i*5:(i+1)*5])\n",
    "\n",
    "  for i in l1:\n",
    "    fig = plt.subplots()\n",
    "    b_plot = df.boxplot(column=i)\n",
    "    b_plot.plot()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(f'boxplots/{i}.png', dpi=100);\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibknBmUWjrR7"
   },
   "source": [
    "#### Show boxplots - Before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAXLGAGujrR7"
   },
   "outputs": [],
   "source": [
    "colNames.remove('Churn')\n",
    "showBoxplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYbcSdMNjrR8"
   },
   "source": [
    "#### Removing outliers\n",
    "\n",
    "The outliers are replaced with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_T3g8BujrR8"
   },
   "outputs": [],
   "source": [
    "for column in colNames:\n",
    "\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "\n",
    "    iqr = q3 - q1\n",
    "    upperLevel = q3 + (iqr * 1.5)\n",
    "    lowerLevel = q1 - (iqr * 1.5)\n",
    "\n",
    "    df[column][df[column] < lowerLevel] = df[column][df[column] > upperLevel] = df[column].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7jojUdZjrR8"
   },
   "source": [
    "#### Show boxplots - After removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwkZFB8AjrR9"
   },
   "outputs": [],
   "source": [
    "if showViz == 1:\n",
    "    #colNames.remove('Churn')\n",
    "    showBoxplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzKDvfxojrR9"
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGip7og87ZN8"
   },
   "outputs": [],
   "source": [
    "# Check for features with type 'object'\n",
    "\n",
    "for column in df:\n",
    "  if df[column].dtype =='object':\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAes5yGkjrR-"
   },
   "source": [
    "#### Min_Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZ0IDi7GBeFW"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaPDH2x1QVwy"
   },
   "outputs": [],
   "source": [
    "def minMaxScale(df):\n",
    "    # Get all the column names to a list.\n",
    "    colNames = df.columns.tolist()[1:len(df.columns.tolist())]\n",
    "\n",
    "    # Apply Min-Max scaler\n",
    "    df[colNames] = scaler.fit_transform(df[colNames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns5gB_nMjrR_"
   },
   "source": [
    "#### Apply Min-Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v41Nl1-uQ7Dl"
   },
   "outputs": [],
   "source": [
    "# Call min-max scaling function\n",
    "minMaxScale(df)\n",
    "\n",
    "# View sample\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYDhK7UOjrSA"
   },
   "source": [
    "###### Show some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dF9Kww9gq1Nt"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rFASaXhjrSB"
   },
   "source": [
    "#### Show boxplots - After scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SVwKGYAjrSB"
   },
   "outputs": [],
   "source": [
    "if showViz == 1:\n",
    "    #colNames.remove('Churn')\n",
    "    showBoxplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The boxplots generated after feature scaling indicates the distribution of some features are very low and near to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOFKIEA9jrSB"
   },
   "source": [
    "## < Data Splitting >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC7L5PFbSQON"
   },
   "source": [
    "### Train & Test Splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKZBcM9DTBNh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train = X_test = df.drop('Churn', axis=1)\n",
    "# y_train = y_test = df['Churn']\n",
    "\n",
    "X_train = X_test = df.drop(df.index)\n",
    "y_train = y_test = df.drop(df.index)\n",
    "\n",
    "# X_train.drop(X_train.index, inplace=True)\n",
    "# X_test.drop(X_test.index, inplace=True)\n",
    "# y_train.drop(y_train.index, inplace=True)\n",
    "# y_test.drop(y_test.index, inplace=True)\n",
    "\n",
    "def splitDataset(df):\n",
    "    # All the columns except 'Churn'\n",
    "    X = df.drop('Churn', axis=1)\n",
    "\n",
    "    # 'Churn' column\n",
    "    y = df['Churn']\n",
    "\n",
    "    # Access dataframes declared globaly\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0FX5VMGT69U"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loew9MtjW2KM"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c91R6fCjrSD"
   },
   "source": [
    "## < Model Selection >\n",
    "\n",
    "The below supervised learning machine learning algorithms are used to analyze the customer churn dataset.\n",
    "\n",
    "- #### K-Nearest Neighbors (KNN)\n",
    "- #### Support Vector Machine (SVM)\n",
    "- #### Random Forest\n",
    "- #### Logistic Regression\n",
    "- #### Decision Tree Classifier\n",
    "- #### Ada Boost Classifier\n",
    "- #### Gradient Boosting Classifier\n",
    "- #### Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0_DCV-6jrSD"
   },
   "source": [
    "### Customized functions used to calculate important parameters for ML selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUz5VbDujrSD"
   },
   "source": [
    "#### Calculating and storing the duration spent for ML processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OF187v5Ux90N"
   },
   "outputs": [],
   "source": [
    "# DataFrame to select the appropriate ML algorithm for this customer churn prediction dataset\n",
    "df_ml_eval = pd.DataFrame({'ATTEMPT':[], 'ALGORITHM':[], 'ALGOINDEX':[], 'TIME':[]})\n",
    "\n",
    "attempt = 0\n",
    "\n",
    "algoList = ['KNN', 'SVM', 'Random Forest', 'Logistic Regression', 'Decision Tree', 'Ada Boost', 'Gradient Boosting', 'Voting']\n",
    "\n",
    "# Function to calculate ML processing time and results, and store records in the 'dfTimeML' DataFrame for analysis\n",
    "def calculateTimeML(t, nameML=None):\n",
    "  global startTime\n",
    "  global endTime\n",
    "\n",
    "  if t == 1:\n",
    "     startTime = datetime.now()\n",
    "  elif t == 2:\n",
    "     endTime = datetime.now()\n",
    "\n",
    "\n",
    "     # Print duration\n",
    "     print(f'{nameML} time : {(endTime-startTime).total_seconds()}')\n",
    "\n",
    "     # Store time in the DataFrame\n",
    "     df_ml_eval.loc[len(df_ml_eval.index)+1] = [attempt, nameML, algoList.index(nameML), (endTime-startTime).total_seconds()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9R5vxdBjrSE"
   },
   "source": [
    "#### Function to generate Confusion Matrix Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VBigXYajrSF"
   },
   "outputs": [],
   "source": [
    "def generateConfusionMatrixGraph(algo, y_test, pred):\n",
    "\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(confusion_matrix(y_test, pred), cmap=\"Blues\",\n",
    "                    annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "\n",
    "    plt.title(f'{algo} Confusion Matrix' ,fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7W8IL9JdjrSF"
   },
   "source": [
    "#### Function to generate Confusion Matrix Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGNMsgwajrSF"
   },
   "outputs": [],
   "source": [
    "def generateConfusionMatrixArray(prediction):\n",
    "    # Assigned the actual and predicted values to a dictionary.\n",
    "    dvalues = {'y_actual': y_test, 'y_predicted': prediction}\n",
    "\n",
    "    # Create a dataframe from dvalues dictionary.\n",
    "    dfcm = pd.DataFrame(dvalues)\n",
    "\n",
    "    # Create the confusion matrix using the dfcm dataframe.\n",
    "    cm = pd.crosstab(dfcm['y_actual'], dfcm['y_predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing 'Yes' and 'No' values with 1 and 0 in y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceYesNo():\n",
    "    # Number of model training attempts\n",
    "    global attempt\n",
    "    \n",
    "    attempt = attempt + 1\n",
    "\n",
    "    # Replacing 'Yes' and 'No' values with 1 and 0 to avoid python errors\n",
    "    y_test.replace({'Yes':1, 'No':0}, inplace=True)\n",
    "    y_train.replace({'Yes':1, 'No':0}, inplace=True)\n",
    "\n",
    "replaceYesNo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1dwprsmjrSG"
   },
   "source": [
    "## < Model Training >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZsENuoSnKXC"
   },
   "source": [
    "### 01 : K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps1RcEHgnOFc"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def trainModel_knn():\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "    model_knn.fit(X_train,y_train)\n",
    "    prediction_knn = model_knn.predict(X_test)\n",
    "    accuracy_knn = model_knn.score(X_test,y_test)\n",
    "    print(\"KNN accuracy :\",accuracy_knn)\n",
    "\n",
    "    calculateTimeML(2, 'KNN')\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test, prediction_knn))\n",
    "    \n",
    "    return (model_knn, prediction_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbguaIzJnyuM"
   },
   "source": [
    "### 02 : Support Vector Machine - SVM\n",
    "\n",
    "##### Since the Support Vector Machine takes a considerable amount of time compared to the other algorithms, SVM was not considered in this research form here onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "A9k-eItPnzR4"
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# calculateTimeML(1)\n",
    "\n",
    "# model_svc = SVC(random_state = 1, probability=True)\n",
    "# model_svc.fit(X_train,y_train)\n",
    "# prediction_svc = model_svc.predict(X_test)\n",
    "# accuracy_svc = model_svc.score(X_test,y_test)\n",
    "# print('SVM accuracy :',accuracy_svc)\n",
    "\n",
    "# calculateTimeML(2, 'SVM')\n",
    "\n",
    "# print('\\nClassification Report')\n",
    "# print(classification_report(y_test, prediction_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJmr4I8Wq7q1"
   },
   "source": [
    "### 03 : Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JuB9fW9iq-3t"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def trainModel_rf():\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_rf = RandomForestClassifier(n_estimators=500 , oob_score = True, n_jobs = -1,\n",
    "                                      random_state =50, max_features = \"sqrt\",\n",
    "                                      max_leaf_nodes = 30)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    prediction_rf = model_rf.predict(X_test)\n",
    "    accuracy_rf = metrics.accuracy_score(y_test, prediction_rf)\n",
    "    print('Random Forest accuracy :', accuracy_rf)\n",
    "\n",
    "    calculateTimeML(2, 'Random Forest')\n",
    "\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test, prediction_rf))\n",
    "    \n",
    "    return (model_rf, prediction_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZqFghwMrtoP"
   },
   "source": [
    "###  04 : Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rOedKGjOrtsR"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def trainModel_lr():\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train,y_train)\n",
    "    prediction_lr = model_lr.predict(X_test)\n",
    "    accuracy_lr = model_lr.score(X_test,y_test)\n",
    "    print(\"Logistic Regression accuracy :\",accuracy_lr)\n",
    "\n",
    "    calculateTimeML(2, 'Logistic Regression')\n",
    "\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test,prediction_lr))\n",
    "    \n",
    "    return (model_lr, prediction_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEfTnLMYtgYT"
   },
   "source": [
    "### 05 : Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "u3duDOqbtgb6"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def trainModel_dt():\n",
    "\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_dt = DecisionTreeClassifier()\n",
    "    model_dt.fit(X_train,y_train)\n",
    "    prediction_dt = model_dt.predict(X_test)\n",
    "    accuracy_dt = model_dt.score(X_test,y_test)\n",
    "    print(\"Decision Tree accuracy is :\",accuracy_dt)\n",
    "\n",
    "    calculateTimeML(2, 'Decision Tree')\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test, prediction_dt))\n",
    "    \n",
    "    return (model_dt, prediction_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIj00mGktgjf"
   },
   "source": [
    "### 06 : Ada Boost Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CMJqG2y8tgnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def trainModel_abc():\n",
    "\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_abc = AdaBoostClassifier()\n",
    "    model_abc.fit(X_train,y_train)\n",
    "    prediction_abc = model_abc.predict(X_test)\n",
    "    accuracy_abc = metrics.accuracy_score(y_test, prediction_abc)\n",
    "    print(\"Ada Boost Classifier accuracy : \", accuracy_abc)\n",
    "\n",
    "    calculateTimeML(2, 'Ada Boost')\n",
    "\n",
    "    print('\\nClassificatin Report')\n",
    "    print(classification_report(y_test, prediction_abc))\n",
    "    \n",
    "    return (model_abc, prediction_abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU-M1a2CtgzV"
   },
   "source": [
    "### 07 : Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OdLx9vRvuL0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def trainModel_gbc():\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    model_gbc = GradientBoostingClassifier()\n",
    "    model_gbc.fit(X_train, y_train)\n",
    "    prediction_gbc = model_gbc.predict(X_test)\n",
    "    accuracy_gbc = accuracy_score(y_test, prediction_gbc)\n",
    "    print(\"Gradient Boosting Classifier : \", accuracy_gbc)\n",
    "\n",
    "    calculateTimeML(2, 'Gradient Boosting')\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test, prediction_gbc))\n",
    "    \n",
    "    return (model_gbc, prediction_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOW-sJE4uMAn"
   },
   "source": [
    "### 08 : Voting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "z0_hh8JSuMFD"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def trainModel_vc():\n",
    "\n",
    "    calculateTimeML(1)\n",
    "\n",
    "    clf_gbc = GradientBoostingClassifier()\n",
    "    clf_lr = LogisticRegression()\n",
    "    clf_abc = AdaBoostClassifier()\n",
    "    model_vc = VotingClassifier(estimators=[('gbc', clf_gbc), ('lr', clf_lr), ('abc', clf_abc)], voting='soft')\n",
    "    model_vc.fit(X_train, y_train)\n",
    "    prediction_vc = model_vc.predict(X_test)\n",
    "    accuracy_vc = accuracy_score(y_test, prediction_vc)\n",
    "    print(f\"Final Accuracy Score {accuracy_vc}\")\n",
    "\n",
    "    calculateTimeML(2, 'Voting')\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test, prediction_vc))\n",
    "    \n",
    "    return (model_vc, prediction_vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelTrainFunctions():\n",
    "    \n",
    "    model_knn, prediction_knn = trainModel_knn()\n",
    "#     model_svc, prediction_knn = trainModel_knn()\n",
    "    model_rf, prediction_rf = trainModel_rf()\n",
    "    model_lr, prediction_lr = trainModel_lr()\n",
    "    model_dt, prediction_dt = trainModel_dt()\n",
    "    model_abc, prediction_abc = trainModel_abc()\n",
    "    model_gbc, prediction_gbc = trainModel_gbc()\n",
    "    model_vc, prediction_vc = trainModel_vc()\n",
    "    \n",
    "    return model_knn, model_rf, model_lr, model_dt, model_abc, model_gbc, model_vc, prediction_knn, prediction_lr, prediction_rf, prediction_dt, prediction_abc, prediction_gbc, prediction_vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling models training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn, model_rf, model_lr, model_dt, model_abc, model_gbc, model_vc, prediction_knn, prediction_lr, prediction_rf, prediction_dt, prediction_abc, prediction_gbc,prediction_vc = runModelTrainFunctions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The total processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zfBsP_kAtg3X"
   },
   "outputs": [],
   "source": [
    "print(f'Total processing time : {(endTime-mainStartTime)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O8VpGpQjrSL"
   },
   "source": [
    "## < Model Evaluation >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T3ej0xnjrSL"
   },
   "source": [
    "### Evaluation Type 1 - Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-JSKR2gjrSL"
   },
   "source": [
    "#### Function to generate confusion matrix graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateConfusionMatrixGraphs_All():\n",
    "    \n",
    "   # global prediction_knn, prediction_rf, prediction_lr, prediction_dt, prediction_abc, prediction_gbc, prediction_vc\n",
    "\n",
    "    generateConfusionMatrixGraph('KNN', y_test, prediction_knn)\n",
    "    # generateConfusionMatrixGraph('SVM', y_test, prediction_svc)\n",
    "    generateConfusionMatrixGraph('Random Forest', y_test, prediction_rf)\n",
    "    generateConfusionMatrixGraph('Logistic Regression', y_test, prediction_lr)\n",
    "    generateConfusionMatrixGraph('Decision Tree', y_test, prediction_dt)\n",
    "    generateConfusionMatrixGraph('Ada Boost', y_test, prediction_abc)\n",
    "    generateConfusionMatrixGraph('Gradient Boosting Classifier', y_test, prediction_gbc)\n",
    "    generateConfusionMatrixGraph('Final', y_test, prediction_vc)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Confusion Matrix graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateConfusionMatrixGraphs_All() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goe6LeLtjrSN"
   },
   "source": [
    "#### Function to create Confusion Matrix Arrays - Accuracy, Sensivity, Specificity, Recall & F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5-IpFQAjrSO"
   },
   "outputs": [],
   "source": [
    "    # Confusion Matrix Arrays of each ML model\n",
    "\n",
    "def confusionMatrixArrays():   \n",
    "        \n",
    "        # K-Nearest Neighbors\n",
    "        cm_knn = generateConfusionMatrixArray(prediction_knn)\n",
    "\n",
    "        # Support vector machine\n",
    "        # cm_svc = generateConfusionMatrixArray(prediction_svc)\n",
    "        \n",
    "        # Random forest\n",
    "        cm_rf = generateConfusionMatrixArray(prediction_rf)\n",
    "        \n",
    "        # Logistic regression\n",
    "        cm_lr = generateConfusionMatrixArray(prediction_lr)\n",
    "\n",
    "        # Decision tree\n",
    "        cm_dt = generateConfusionMatrixArray(prediction_dt)\n",
    "\n",
    "        # Ada boost\n",
    "        cm_abc = generateConfusionMatrixArray(prediction_abc)\n",
    "\n",
    "        # Gradient boosting\n",
    "        cm_gbc = generateConfusionMatrixArray(prediction_gbc)\n",
    "\n",
    "        # Voting\n",
    "        cm_vc = generateConfusionMatrixArray(prediction_vc)\n",
    "\n",
    "        return (cm_knn, cm_rf, cm_lr, cm_dt, cm_abc, cm_gbc, cm_vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to create Confusion Matrix Arrays - Accuracy, Sensivity, Specificity, Recall & F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn, cm_rf, cm_lr, cm_dt, cm_abc, cm_gbc, cm_vc = confusionMatrixArrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0An5e3zjrSO"
   },
   "source": [
    "#### Function to append 'df_ml_eval' DataFrame with sensivity and specificity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendConfusionMatrixResults():\n",
    "    \n",
    "    df_ml_eval['TP'] = [cm_knn[0][0], cm_rf[0][0], cm_lr[0][0], cm_dt[0][0], cm_abc[0][0], cm_gbc[0][0], cm_vc[0][0]]\n",
    "    df_ml_eval['TN'] = [cm_knn[1][1], cm_rf[1][1], cm_lr[1][1], cm_dt[1][1], cm_abc[1][1], cm_gbc[1][1], cm_vc[1][1]]\n",
    "    df_ml_eval['FP'] = [cm_knn[1][0], cm_rf[1][0], cm_lr[1][0], cm_dt[1][0], cm_abc[1][0], cm_gbc[1][0], cm_vc[1][0]]\n",
    "    df_ml_eval['FN'] = [cm_knn[0][1], cm_rf[0][1], cm_lr[0][1], cm_dt[0][1], cm_abc[0][1], cm_gbc[0][1], cm_vc[0][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to append 'df_ml_eval' DataFrame with sensivity and specificity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendConfusionMatrixResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jo9Kl7q3jrSP"
   },
   "source": [
    "#### Function to calculating accuracy, sensitivity, specificity, recall & F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TOGf7E3jrSP"
   },
   "outputs": [],
   "source": [
    "def calculateAccSensiSpeciRecallF1Score():\n",
    "\n",
    "    # The total of predicted positives and predicted negatives of all the predictions\n",
    "    df_ml_eval['ACCURACY'] = round(((df_ml_eval['TP']+df_ml_eval['TN'])/(df_ml_eval['TP'] + df_ml_eval['TN'] + df_ml_eval['FP']+df_ml_eval['FN'])*100), 2)\n",
    "\n",
    "    # Precision : Sensitivity - Predicted true positives by predicted total positives\n",
    "    df_ml_eval['SENSITIVITY'] = round((df_ml_eval['TP']/(df_ml_eval['TP']+df_ml_eval['FP'])*100), 2)\n",
    "\n",
    "    # Precision : Sepcificity - Predicted true negatives by predicted total negatives\n",
    "    df_ml_eval['SPECIFICITY'] = round((df_ml_eval['TN']/(df_ml_eval['TN']+df_ml_eval['FN'])*100), 2)\n",
    "\n",
    "    # Predicted positives of actual positve values by all the actual positives\n",
    "    df_ml_eval['RECALL'] = round(((df_ml_eval['TP'])/(df_ml_eval['TP']+df_ml_eval['FN'])*100), 2)\n",
    "\n",
    "\n",
    "    df_ml_eval['F1_SCORE'] = ((df_ml_eval['SENSITIVITY'] * df_ml_eval['RECALL']) / (df_ml_eval['SENSITIVITY'] + df_ml_eval['RECALL']))*2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function for calculating accuracy, sensitivity, specificity, recall & F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccSensiSpeciRecallF1Score()\n",
    "\n",
    "df_ml_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7qJLw9hjrSQ"
   },
   "source": [
    "#### Function for plotting accuracy, sensitivity, specificity, recall, F1_score & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_Pq92QmjrSQ"
   },
   "outputs": [],
   "source": [
    "def modelComparisionPlot(fName):\n",
    "\n",
    "    fig, ((ax0, ax1), (ax2, ax3), (ax4, ax5)) = plt.subplots(ncols=2, nrows=3, figsize=(15, 12), sharex=True)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    bar_container0 = ax0.bar(df_ml_eval['ALGORITHM'], df_ml_eval['ACCURACY'])\n",
    "    ax0.bar_label(bar_container0)\n",
    "    ax0.scatter(df_ml_eval['ALGORITHM'], df_ml_eval['ACCURACY'])\n",
    "    ax0.plot(df_ml_eval['ALGORITHM'], df_ml_eval['ACCURACY'])\n",
    "    ax0.set(title='Accuracy Graph');\n",
    "    ax0.grid(True)\n",
    "\n",
    "    bar_container1 = ax1.bar(df_ml_eval['ALGORITHM'], df_ml_eval['SENSITIVITY'])\n",
    "    ax1.bar_label(bar_container1)\n",
    "    ax1.scatter(df_ml_eval['ALGORITHM'], df_ml_eval['SENSITIVITY'])\n",
    "    ax1.plot(df_ml_eval['ALGORITHM'], df_ml_eval['SENSITIVITY'])\n",
    "    ax1.set(title='Sensitivity Graph')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    bar_container2 = ax2.bar(df_ml_eval['ALGORITHM'], df_ml_eval['SPECIFICITY'])\n",
    "    ax2.bar_label(bar_container2)\n",
    "    ax2.scatter(df_ml_eval['ALGORITHM'], df_ml_eval['SPECIFICITY'])\n",
    "    ax2.plot(df_ml_eval['ALGORITHM'], df_ml_eval['SPECIFICITY'])\n",
    "    ax2.set(title='Specificity Graph')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    bar_container3 = ax3.bar(df_ml_eval['ALGORITHM'], df_ml_eval['RECALL'])\n",
    "    ax3.bar_label(bar_container3)\n",
    "    ax3.scatter(df_ml_eval['ALGORITHM'], df_ml_eval['RECALL'])\n",
    "    ax3.plot(df_ml_eval['ALGORITHM'], df_ml_eval['RECALL'])\n",
    "    ax3.set(title='Recall Graph')\n",
    "    ax3.grid(True)\n",
    "\n",
    "    bar_container4 = ax4.bar(df_ml_eval['ALGORITHM'], df_ml_eval['F1_SCORE'])\n",
    "    ax4.bar_label(bar_container4)\n",
    "    ax4.scatter(df_ml_eval['ALGORITHM'], df_ml_eval['F1_SCORE'])\n",
    "    ax4.plot(df_ml_eval['ALGORITHM'], df_ml_eval['F1_SCORE'])\n",
    "    ax4.set(title='F1-Score Graph')\n",
    "    ax4.grid(True)\n",
    "\n",
    "    bar_container5 = ax5.bar(df_ml_eval['ALGORITHM'], df_ml_eval['TIME'])\n",
    "    ax5.bar(df_ml_eval['ALGORITHM'], df_ml_eval['TIME'])\n",
    "    #ax5.bar_label(bar_container1)\n",
    "    ax5.set(title='Processed Time', xlabel='', ylabel='Time (seconds)')\n",
    "    ax5.grid(True)\n",
    "    plt.xticks(rotation=70);\n",
    "\n",
    "    fig.suptitle(fName, fontsize = 16, weight = 'extra bold', y=1)\n",
    "    plt.savefig(f'{fName}.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function for plotting accuracy, sensitivity, specificity, recall, F1_score & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComparisionPlot('Bar Graphs - Before Columns Removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMSKBJiWjrSQ"
   },
   "source": [
    "### Evaluation Type 2 : Receiver Operating Characteristic (ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tyn_qfXQjrSQ"
   },
   "source": [
    "#### Function to generating ROC graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaCLj6BajrSQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def generateROCgraphs(fName):\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=4, figsize=(10, 12))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    models = [model_knn, model_rf, model_lr, model_dt, model_abc, model_gbc, model_vc]\n",
    "    modelN = ['KNN', 'Random Forest', 'Logistic Regression', 'Decision Tree', 'Ada Boost', 'Gradient Boosting', 'VC']\n",
    "\n",
    "    j = 0\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(models)):\n",
    "\n",
    "        y_pred_prob = models[i].predict_proba(X_test)[:,1]\n",
    "        fpr_rf, tpr_rf, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "        ax[j][k].plot([0, 1], [0, 1], 'k--' )\n",
    "        ax[j][k].plot(fpr_rf, tpr_rf, label=modelN[i],color = \"r\")\n",
    "        ax[j][k].set(title=f'{modelN[i]} ROC Curve', xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "        if k == 1:\n",
    "            j = j + 1\n",
    "            k = 0\n",
    "            continue\n",
    "\n",
    "        k = k + 1\n",
    "    \n",
    "    fig.suptitle(fName, fontsize = 16, weight = 'extra bold', y=1)\n",
    "    plt.savefig(f'{fName}.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to generate ROC graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateROCgraphs('ROC Curves - Before Columns Removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain the models after removing some features : Analiyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwantedColumns = ['ThreewayCalls', 'CallForwardingCalls', 'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', \n",
    "                   'RVOwner', 'Homeownership', 'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'RetentionCalls', \n",
    "                   'RetentionOffersAccepted', 'NewCellphoneUser', 'NotNewCellphoneUser', 'ReferralsMadeBySubscriber', \n",
    "                   'OwnsMotorcycle', 'AdjustmentsToCreditRating', 'HandsetPrice', 'MadeCallToRetentionTeam', \n",
    "                   'CreditRating_1-Highest', 'CreditRating_3-Good', 'CreditRating_4-Medium', 'CreditRating_5-Low', \n",
    "                   'CreditRating_6-VeryLow', 'CreditRating_7-Lowest', 'PrizmCode_Rural', 'PrizmCode_Town', \n",
    "                   'Occupation_Clerical', 'Occupation_Crafts', 'Occupation_Homemaker', 'Occupation_Professional', \n",
    "                   'Occupation_Retired', 'Occupation_Self', 'Occupation_Student', 'MaritalStatus_No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(unwantedColumns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning results dataframe re-initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_eval = pd.DataFrame({'ATTEMPT':[], 'ALGORITHM':[], 'ALGOINDEX':[], 'TIME':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-initializing the X_train, X_test, y_train, y_test objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_test = df.drop(df.index)\n",
    "y_train = y_test = df.drop(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDataset(df)\n",
    "replaceYesNo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling models training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn, model_rf, model_lr, model_dt, model_abc, model_gbc, model_vc, prediction_knn, prediction_lr, prediction_rf, prediction_dt, prediction_abc, prediction_gbc,prediction_vc = runModelTrainFunctions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Confusion Matrix graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateConfusionMatrixGraphs_All()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to create Confusion Matrix Arrays - Accuracy, Sensivity, Specificity, Recall & F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn, cm_rf, cm_lr, cm_dt, cm_abc, cm_gbc, cm_vc = confusionMatrixArrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to append 'df_ml_eval' DataFrame with sensivity and specificity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendConfusionMatrixResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function for calculating accuracy, sensitivity, specificity, recall & F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateAccSensiSpeciRecallF1Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function for plotting accuracy, sensitivity, specificity, recall, F1_score & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComparisionPlot('BarGraph_AfterColumnsRemoved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function to generate ROC graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateROCgraphs('ROC_AfterColumnsRemoved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVDWz0n3jrSR"
   },
   "source": [
    "## < Finalizing The Most Suitable Model >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aScoW0n-jrSR"
   },
   "source": [
    "## < Model Deployment >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKHZokg8jrSR"
   },
   "source": [
    "### Importing the 'joblib' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRteQ8DKjrSR"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdHqODVxjrSR"
   },
   "source": [
    "### Save the model as a file\n",
    "\n",
    "This exported trained model can be used to predict customer churns in the telcom organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpXjkiStjrSS"
   },
   "outputs": [],
   "source": [
    "joblib.dump(model_lr, 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgXrCN8qjrSS"
   },
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTFJNlZvjrSS"
   },
   "outputs": [],
   "source": [
    "model = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxCxZiAHjrSS"
   },
   "source": [
    "### Function to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFA-EPsejrST"
   },
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "\n",
    "    # Drop 'Churn' column from the dataset\n",
    "    dfHoldout.drop('Churn', axis=1, inplace=True)\n",
    "\n",
    "    # Apply the custom functions to prepare the dataset for the deployed ML model\n",
    "    dropColumns(df)\n",
    "    imputeNA(df)\n",
    "    labelEncoding(df)\n",
    "    df = oneHotEncoding(df)\n",
    "    minMaxScale(df)\n",
    "    df.drop(unwantedColumns, axis=1, inplace=True)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # Move predicitions in a new column 'Churn'\n",
    "    df['Churn'] = predictions\n",
    "\n",
    "    # Replace 0 and 1 with 'No' and 'Yes'\n",
    "    df['Churn'].replace({0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n416tEPTjrST"
   },
   "source": [
    "### Read the data to be prodicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWS03dQmjrST"
   },
   "outputs": [],
   "source": [
    "# There are 20,000 number of records in the dataset to be predicted\n",
    "dfHoldout = pd.read_csv('telcomHoldout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSMgx0Q1jrST"
   },
   "source": [
    "### Call the 'predict' function and assign the new dataset with the new 'Churn' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhJapLY4jrSU"
   },
   "outputs": [],
   "source": [
    "dfHoldout = predict(dfHoldout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgYNcHPxjrSU"
   },
   "source": [
    "### View the predicted churn column of the  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0u03zVStjrSU"
   },
   "outputs": [],
   "source": [
    "dfHoldout.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total time : {(datetime.now()-mainStartTime)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
